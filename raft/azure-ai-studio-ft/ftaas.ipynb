{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT\n",
    "\n",
    "## Synthetic data generation phase\n",
    "\n",
    "### Load domain specific documents we want to optimize RAG for\n",
    "\n",
    "TODO\n",
    "\n",
    "### Generate Q/A/CoT fine-tuning dataset using RAFT from the domain specific documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"../sample_data/UC_Berkeley_short.pdf\"\n",
    "ds_path = \"ucb-short\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ../raft.py \\\n",
    "    --datapath $doc_path \\\n",
    "    --output $ds_path \\\n",
    "    --distractors 3 \\\n",
    "    --doctype pdf \\\n",
    "    --chunk_size 512 \\\n",
    "    --questions 2 \\\n",
    "    --completion_model gpt-4-turbo \\\n",
    "    --embedding_model text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert generated HuggingFace arrow dataset to JSONL format suitable for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning phase\n",
    "\n",
    "### Loading the model to fine-tune\n",
    "\n",
    "We will use the `llama-2-7b` model to show how user can finetune a model for text-completion task. If you opened this notebook from a specific model card, remember to replace the specific model name. Optionally, if you need to fine tune a model that is available on HuggingFace, but not available in `azureml` system registry, to do so [import](https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/system/import/import_model_into_registry.ipynb) the model.\n",
    "\n",
    "### Outline\n",
    "* Pick a model to fine-tune.\n",
    "* Pick and explore training data.\n",
    "* Configure the fine tuning job.\n",
    "* Run the fine tuning job.\n",
    "* Review training metrics.\n",
    "* Deploy the fine tuned model for real time inference. [TODO]\n",
    "* Clean up resources.  [TODO]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Connect to `azureml` system registry\n",
    "* Set an optional experiment name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies by running below cell. This is not an optional step if running in a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-storage-file-datalake==12.14.0\n",
    "%pip install azure-ai-ml\n",
    "%pip install azure-identity\n",
    "\n",
    "%pip install mlflow\n",
    "%pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for download hugging face datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets==2.9.0\n",
    "%pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
      "\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint.\n",
      "\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n",
      "\tAzureCliCredential: Azure CLI not found on path\n",
      "\tAzurePowerShellCredential: PowerShell is not installed\n",
      "\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n",
      "Found the config file in: ./config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ML Client configuration from config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
    "    print(\"Loaded ML Client configuration from config.json\")\n",
    "except:\n",
    "    print(\"Loading ML Client configuration directly\")\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "        resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "        workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    )\n",
    "\n",
    "# the models, fine tuning pipelines and environments are available in the AzureML system registry, \"azureml\"\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml\")\n",
    "registry_ml_client_meta = MLClient(credential, registry_name=\"azureml-meta\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a foundation model to fine tune\n",
    "\n",
    "Decoder based LLM models like `llama` performs well on `text-completion` tasks, we need to finetune the model for our specific purpose in order to use it. You can browse these models in the Model Catalog in the AzureML Studio, filtering by the `text-completion` task. In this example, we use the `llama-2-7b` model. If you have opened this notebook for a different model, replace the model name and version accordingly. \n",
    "\n",
    "Note the model id property of the model. This will be passed as input to the fine tuning job. This is also available as the `Asset ID` field in model details page in AzureML Studio Model Catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model name: Llama-2-7b, version: 20, id: azureml://registries/azureml-meta/models/Llama-2-7b/versions/20 for fine tuning\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Llama-2-7b\"\n",
    "foundation_model = registry_ml_client_meta.models.get(model_name, label=\"latest\")\n",
    "print(f\"Using model name: {foundation_model.name}, version: {foundation_model.version}, id: {foundation_model.id} for fine tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants._common import AssetTypes\n",
    "from azure.ai.ml.entities._inputs_outputs import Input\n",
    "mlflow_model_llama = Input(\n",
    "        type=AssetTypes.MLFLOW_MODEL, path=foundation_model.id\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pick the dataset for fine-tuning the model\n",
    "\n",
    "We use the [samsum](https://huggingface.co/datasets/samsum) dataset. The next few cells show basic data preparation for fine tuning:\n",
    "* Visualize some data rows\n",
    "* Preprocess the data and format it in required format. This is an important step for performing text completion as we add the required sequences/separators in the data. This is how we repurpose the text-completion task to any specific task like summarization, translation, text-completion, etc.\n",
    "* While fintuning, text column is concatenated with ground_truth column to produce finetuning input. Hence, the data should be prepared such that `text + ground_truth` is your actual finetuning data.\n",
    "* bos and eos tokens are added to the data by finetuning pipeline, you do not need to add it explicitly \n",
    "* We want this sample to run quickly, so save smaller `train`, `validation` and `test` files containing 10% of the original. This means the fine tuned model will have lower accuracy, hence it should not be put to real-world use. \n",
    "\n",
    "##### Here is an example of how the data should look like\n",
    "\n",
    "text completion requires the training data to include at least 2 fields – one for ‘text’ and ‘ground_truth’ like in this example. The below examples are from Samsum dataset. \n",
    "\n",
    "Original dataset:\n",
    "\n",
    "| dialogue (text) | summary (ground_truth) |\n",
    "| :- | :- |\n",
    "| Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric: I know! And shows how Americans see Russian ;)\\r\\nRob: And it's really funny!\\r\\nEric: I know! I especially like the train part!\\r\\nRob: Hahaha! No one talks to the machine like that!\\r\\nEric: Is this his only stand-up?\\r\\nRob: Idk. I'll check.\\r\\nEric: Sure.\\r\\nRob: Turns out no! There are some of his stand-ups on youtube.\\r\\nEric: Gr8! I'll watch them now!\\r\\nRob: Me too!\\r\\nEric: MACHINE!\\r\\nRob: MACHINE!\\r\\nEric: TTYL?\\r\\nRob: Sure :) | Eric and Rob are going to watch a stand-up on youtube. | \n",
    "| Will: hey babe, what do you want for dinner tonight?\\r\\nEmma:  gah, don't even worry about it tonight\\r\\nWill: what do you mean? everything ok?\\r\\nEmma: not really, but it's ok, don't worry about cooking though, I'm not hungry\\r\\nWill: Well what time will you be home?\\r\\nEmma: soon, hopefully\\r\\nWill: you sure? Maybe you want me to pick you up?\\r\\nEmma: no no it's alright. I'll be home soon, i'll tell you when I get home. \\r\\nWill: Alright, love you. \\r\\nEmma: love you too. | Emma will be home soon and she will let Will know. | \n",
    "\n",
    "Formatted dataset the user might pass:\n",
    "\n",
    "| text (text) | summary (ground_truth) |\n",
    "| :- | :- |\n",
    "| Summarize this dialog:\\nEric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric: I know! And shows how Americans see Russian ;)\\r\\nRob: And it's really funny!\\r\\nEric: I know! I especially like the train part!\\r\\nRob: Hahaha! No one talks to the machine like that!\\r\\nEric: Is this his only stand-up?\\r\\nRob: Idk. I'll check.\\r\\nEric: Sure.\\r\\nRob: Turns out no! There are some of his stand-ups on youtube.\\r\\nEric: Gr8! I'll watch them now!\\r\\nRob: Me too!\\r\\nEric: MACHINE!\\r\\nRob: MACHINE!\\r\\nEric: TTYL?\\r\\nRob: Sure :)\\n---\\nSummary:\\n | Eric and Rob are going to watch a stand-up on youtube. | \n",
    "| Summarize this dialog:\\nWill: hey babe, what do you want for dinner tonight?\\r\\nEmma:  gah, don't even worry about it tonight\\r\\nWill: what do you mean? everything ok?\\r\\nEmma: not really, but it's ok, don't worry about cooking though, I'm not hungry\\r\\nWill: Well what time will you be home?\\r\\nEmma: soon, hopefully\\r\\nWill: you sure? Maybe you want me to pick you up?\\r\\nEmma: no no it's alright. I'll be home soon, i'll tell you when I get home. \\r\\nWill: Alright, love you. \\r\\nEmma: love you too. \\n---\\nSummary:\\n | Emma will be home soon and she will let Will know. | \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents for solo backpacking in stock?\\nExample answer:</td>\n",
       "      <td>{\"intent\": \"chat\"}STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents in stock that can accommodate two people?\\nExample answer:</td>\n",
       "      <td>{\"intent\": \"chat\"}STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents in stock?\\nExample answer:</td>\n",
       "      <td>{\"intent\": \"chat\"}STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents on sale this month?\\nExample answer:</td>\n",
       "      <td>{\"intent\": \"chat\"}STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents on sale this week?\\nExample answer:</td>\n",
       "      <td>{\"intent\": \"chat\"}STOP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                        prompt  \\\n",
       "0  You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents for solo backpacking in stock?\\nExample answer:               \n",
       "1  You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents in stock that can accommodate two people?\\nExample answer:    \n",
       "2  You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents in stock?\\nExample answer:                                    \n",
       "3  You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents on sale this month?\\nExample answer:                          \n",
       "4  You are a robot that only outputs JSON. You reply in JSON format with the field 'intent' which can only take values 'support' or 'chat'.\\n\\nExample question: Do you have any lightweight tents on sale this week?\\nExample answer:                           \n",
       "\n",
       "               completion  \n",
       "0  {\"intent\": \"chat\"}STOP  \n",
       "1  {\"intent\": \"chat\"}STOP  \n",
       "2  {\"intent\": \"chat\"}STOP  \n",
       "3  {\"intent\": \"chat\"}STOP  \n",
       "4  {\"intent\": \"chat\"}STOP  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the ./samsum-dataset/train.jsonl file into a pandas dataframe and show the first 5 rows\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", 0\n",
    ")  # set the max column width to 0 to display the full text\n",
    "df = pd.read_json(\"./dataset/intents-pc-16k-1000.jsonl\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# split dataset into 80%/20%\n",
    "import numpy as np\n",
    "train_df, validation_df = np.split(df, [int(.8*len(df))])\n",
    "train_df.to_json(\"./dataset/train.jsonl\", orient=\"records\", lines=True)\n",
    "validation_df.to_json(\"./dataset/validation.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(\"./dataset/intents-pc-16k-test-1999.jsonl\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit the fine tuning job using the the model and data as inputs\n",
    " \n",
    "Create the job that uses the `text-generation` pipeline component. [Learn more](https://github.com/Azure/azureml-assets/blob/main/assets/training/finetune_acft_hf_nlp/components/pipeline_components/text_generation/README.md) about all the parameters supported for fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define finetune parameters\n",
    "\n",
    "Finetune parameters can be grouped into 2 categories - training parameters, optimization parameters\n",
    "\n",
    "Training parameters define the training aspects such as - \n",
    "1. the optimizer, scheduler to use\n",
    "2. the metric to optimize the finetune\n",
    "3. number of training steps and the batch size\n",
    "and so on\n",
    "\n",
    "Optimization parameters help in optimizing the GPU memory and effectively using the compute resources. Below are few of the parameters that belong to this category. _The optimization parameters differs for each model and are packaged with the model to handle these variations._\n",
    "1. enable the deepspeed, ORT and LoRA\n",
    "2. enable mixed precision training\n",
    "2. enable multi-node training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities._inputs_outputs import Input\n",
    "training_data=Input(type=\"uri_file\", path=\"./dataset/train.jsonl\")\n",
    "validation_data=Input(type=\"uri_file\", path=\"./dataset/validation.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create FineTuning job object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.ai.ml.entities._job.finetuning.custom_model_finetuning_job import CustomModelFineTuningJob\n",
    "import uuid\n",
    "from azure.ai.ml._restclient.v2024_01_01_preview.models import (\n",
    "    FineTuningTaskType,\n",
    ")\n",
    "from azure.ai.ml.entities._inputs_outputs import Output\n",
    "\n",
    "guid = uuid.uuid4()\n",
    "short_guid = str(guid)[:8]\n",
    "\n",
    "custom_model_finetuning_job = CustomModelFineTuningJob(\n",
    "    task=FineTuningTaskType.TEXT_COMPLETION,\n",
    "    training_data=training_data,\n",
    "    validation_data=validation_data,\n",
    "    hyperparameters={\n",
    "        \"per_device_train_batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.00002\",\n",
    "        \"num_train_epochs\": \"1\",\n",
    "    },\n",
    "    model=mlflow_model_llama,\n",
    "    display_name=f\"llama-display-name-{short_guid}\",\n",
    "    name=f\"llama-{short_guid}\",\n",
    "    experiment_name=\"llama-finetuning-experiment\",\n",
    "    tags={\"agent\": \"gorilla-raft-notebook\"},\n",
    "    properties={\"rocks\": True},\n",
    "    outputs={\"registered_model\": Output(type=\"mlflow_model\", name=f\"llama-finetune-registered-{short_guid}\")},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit FineTuningJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'azure.core.exceptions.ServiceRequestError'>:\n<urllib3.connection.HTTPSConnection object at 0xfffef412f4c0>: Failed to resolve 'stcviberkele092349915883.blob.core.windows.net' ([Errno -2] Name or service not known)\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceRequestError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:1278\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[0;34m(self, entry, base_path)\u001b[0m\n\u001b[1;32m   1277\u001b[0m local_path \u001b[38;5;241m=\u001b[39m Path(base_path \u001b[38;5;129;01mor\u001b[39;00m Path\u001b[38;5;241m.\u001b[39mcwd(), entry\u001b[38;5;241m.\u001b[39mpath)\u001b[38;5;241m.\u001b[39mresolve()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1278\u001b[0m entry\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[43m_upload_and_generate_remote_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatastore_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatastore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# TODO : Move this part to a common place\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:415\u001b[0m, in \u001b[0;36m_upload_and_generate_remote_uri\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress)\u001b[0m\n\u001b[1;32m    414\u001b[0m asset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[0;32m--> 415\u001b[0m artifact_info \u001b[38;5;241m=\u001b[39m \u001b[43m_upload_to_datastore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatastore_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatastore_operation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatastore_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatastore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43masset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m path \u001b[38;5;241m=\u001b[39m artifact_info\u001b[38;5;241m.\u001b[39mrelative_path\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:387\u001b[0m, in \u001b[0;36m_upload_to_datastore\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress, asset_name, asset_version, asset_hash, ignore_file, sas_uri, blob_uri)\u001b[0m\n\u001b[1;32m    386\u001b[0m     asset_hash \u001b[38;5;241m=\u001b[39m get_object_hash(path, ignore_file)\n\u001b[0;32m--> 387\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mupload_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatastore_operation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatastore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43masset_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43masset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43masset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43msas_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msas_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blob_uri:\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:246\u001b[0m, in \u001b[0;36mupload_artifact\u001b[0;34m(local_path, datastore_operation, operation_scope, datastore_name, asset_hash, show_progress, asset_name, asset_version, ignore_file, sas_uri)\u001b[0m\n\u001b[1;32m    244\u001b[0m     storage_client \u001b[38;5;241m=\u001b[39m get_storage_client(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdatastore_info)\n\u001b[0;32m--> 246\u001b[0m artifact_info \u001b[38;5;241m=\u001b[39m \u001b[43mstorage_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43masset_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m artifact \u001b[38;5;241m=\u001b[39m ArtifactStorageInfo(\n\u001b[1;32m    256\u001b[0m     name\u001b[38;5;241m=\u001b[39martifact_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    257\u001b[0m     version\u001b[38;5;241m=\u001b[39martifact_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     is_file\u001b[38;5;241m=\u001b[39mPath(local_path)\u001b[38;5;241m.\u001b[39mis_file(),\n\u001b[1;32m    266\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_blob_storage_helper.py:130\u001b[0m, in \u001b[0;36mBlobStorageClient.upload\u001b[0;34m(self, source, name, version, ignore_file, asset_hash, show_progress)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator_file \u001b[38;5;241m=\u001b[39m dest\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_blob_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m upload_file(\n\u001b[1;32m    132\u001b[0m     storage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[1;32m    137\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_blob_storage_helper.py:213\u001b[0m, in \u001b[0;36mBlobStorageClient.check_blob_exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    208\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    209\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    210\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mARTIFACT,\n\u001b[1;32m    211\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    212\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_artifacts/_blob_storage_helper.py:172\u001b[0m, in \u001b[0;36mBlobStorageClient.check_blob_exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m legacy_blob_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_client\u001b[38;5;241m.\u001b[39mget_blob_client(blob\u001b[38;5;241m=\u001b[39mlegacy_indicator_file)\n\u001b[0;32m--> 172\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[43mblob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_blob_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m metadata \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_blob_client.py:1360\u001b[0m, in \u001b[0;36mBlobClient.get_blob_properties\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m partial(deserialize_pipeline_response_into_cls, cls_method)\n\u001b[0;32m-> 1360\u001b[0m     blob_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43msnapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlease_access_conditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccess_conditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodified_access_conditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmod_conditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdeserialize_blob_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpk_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpk_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_generated/operations/_blob_operations.py:1892\u001b[0m, in \u001b[0;36mBlobOperations.get_properties\u001b[0;34m(self, snapshot, version_id, timeout, request_id_parameter, lease_access_conditions, cpk_info, modified_access_conditions, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m _stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1892\u001b[0m pipeline_response: PipelineResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1896\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:230\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 86 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/policies/_redirect.py:197\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_shared/policies.py:549\u001b[0m, in \u001b[0;36mStorageRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retry_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_shared/policies.py:523\u001b[0m, in \u001b[0;36mStorageRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_retry(response, retry_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_shared/policies.py:312\u001b[0m, in \u001b[0;36mStorageResponseHook.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    309\u001b[0m response_callback \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_callback\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    310\u001b[0m     request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response_hook\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_callback)\n\u001b[0;32m--> 312\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m will_retry \u001b[38;5;241m=\u001b[39m is_retry(response, request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/_base.py:119\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    116\u001b[0m cleanup_kwargs_for_transport(request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResponse(\n\u001b[1;32m    118\u001b[0m     request\u001b[38;5;241m.\u001b[39mhttp_request,\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    120\u001b[0m     context\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mcontext,\n\u001b[1;32m    121\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_shared/base_client.py:336\u001b[0m, in \u001b[0;36mTransportWrapper.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/storage/blob/_shared/base_client.py:336\u001b[0m, in \u001b[0;36mTransportWrapper.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/pipeline/transport/_requests_basic.py:386\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[0;34m(self, request, proxies, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_rest(request):\n",
      "\u001b[0;31mServiceRequestError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0xfffef412f4c0>: Failed to resolve 'stcviberkele092349915883.blob.core.windows.net' ([Errno -2] Name or service not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:663\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_or_upload_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationException, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:1082\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, FineTuningJob):\n\u001b[0;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_finetuning_job_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, Spark):\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:1123\u001b[0m, in \u001b[0;36mJobOperations._resolve_finetuning_job_inputs\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, FineTuningVertical):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# self._resolve_job_input(job.model, job._base_path)\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_job_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mvalidation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:1291\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[0;34m(self, entry, base_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1292\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1294\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m   1295\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported input path value are ARM id, AzureML id, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremote uri or local path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1297\u001b[0m         ),\n\u001b[1;32m   1298\u001b[0m         error\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   1299\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m   1300\u001b[0m         error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1301\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValidationException\u001b[0m: Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'azure.core.exceptions.ServiceRequestError'>:\n<urllib3.connection.HTTPSConnection object at 0xfffef412f4c0>: Failed to resolve 'stcviberkele092349915883.blob.core.windows.net' ([Errno -2] Name or service not known)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m created_job \u001b[38;5;241m=\u001b[39m \u001b[43mworkspace_ml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_model_finetuning_job\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m created_job\u001b[38;5;241m.\u001b[39mstudio_url\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:368\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 368\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    371\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:665\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationException, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m     \u001b[43mlog_and_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m git_props \u001b[38;5;241m=\u001b[39m get_git_properties()\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/gorilla/raft/.venv/lib/python3.10/site-packages/azure/ai/ml/_exception_helper.py:337\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(formatted_error)\n",
      "\u001b[0;31mException\u001b[0m: \n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'azure.core.exceptions.ServiceRequestError'>:\n<urllib3.connection.HTTPSConnection object at 0xfffef412f4c0>: Failed to resolve 'stcviberkele092349915883.blob.core.windows.net' ([Errno -2] Name or service not known)\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "created_job = workspace_ml_client.jobs.create_or_update(custom_model_finetuning_job)\n",
    "created_job.studio_url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Review training and evaluation metrics\n",
    "Viewing the job in AzureML studio is the best way to analyze logs, metrics and outputs of jobs. You can create custom charts and compare metics across different jobs. See https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?tabs=interactive#view-jobsruns-information-in-the-studio to learn more. \n",
    "\n",
    "However, we may need to access and review metrics programmatically for which we will use MLflow, which is the recommended client for logging and querying metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow, json\n",
    "\n",
    "mlflow_tracking_uri = workspace_ml_client.workspaces.get(\n",
    "    workspace_ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "# concat 'tags.mlflow.rootRunId=' and pipeline_job.name in single quotes as filter variable\n",
    "filter = \"tags.mlflow.rootRunId='\" + created_job.id + \"'\"\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name], filter_string=filter, output_format=\"list\"\n",
    ")\n",
    "training_run = None\n",
    "evaluation_run = None\n",
    "# get the training and evaluation runs.\n",
    "# using a hacky way till 'Bug 2320997: not able to show eval metrics in FT notebooks - mlflow client now showing display names' is fixed\n",
    "for run in runs:\n",
    "    # check if run.data.metrics.epoch exists\n",
    "    if \"epoch\" in run.data.metrics:\n",
    "        training_run = run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_run:\n",
    "    print(\"Training metrics:\\n\\n\")\n",
    "    print(json.dumps(training_run.data.metrics, indent=2))\n",
    "else:\n",
    "    print(\"No Training job found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Deploy the fine tuned model to an online endpoint [TODO: Need some work]\n",
    "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    ProbeSettings,\n",
    "    OnlineRequestSettings,\n",
    ")\n",
    "\n",
    "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "\n",
    "online_endpoint_name = \"samsum-textgen-\" + timestamp\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \"\n",
    "    + registered_model.name\n",
    "    + \", fine tuned model for samsum textgen\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find here the list of SKU's supported for deployment - [Managed online endpoints SKU list](https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"demo\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_E64s_v3\",\n",
    "    instance_count=1,\n",
    "    liveness_probe=ProbeSettings(initial_delay=600),\n",
    "    request_settings=OnlineRequestSettings(request_timeout_ms=90000),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test the endpoint with sample data\n",
    "\n",
    "We will fetch some sample data from the test dataset and submit to online endpoint for inference. We will then show the display the scored labels alongside the ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ./samsum-dataset/small_test.jsonl into a pandas dataframe\n",
    "test_df = pd.read_json(\"./samsum-dataset/small_test.jsonl\", lines=True)\n",
    "# take 5 random samples\n",
    "test_df = test_df.sample(n=2)\n",
    "# rebuild index\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "# rename the label_string column to ground_truth_label\n",
    "test_df = test_df.rename(columns={\"label_string\": \"ground_truth_label\"})\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a json object with the key as \"input_data\" and value as a list of values from the text column of the test dataframe\n",
    "test_json = {\"input_data\": {\"text\": list(test_df[\"text\"])}}\n",
    "# save the json object to a file named sample_score.json in the ./samsum-dataset folder\n",
    "with open(\"./samsum-dataset/sample_score.json\", \"w\") as f:\n",
    "    json.dump(test_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the sample_score.json file using the online endpoint with the azureml endpoint invoke method\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"demo\",\n",
    "    request_file=\"./samsum-dataset/sample_score.json\",\n",
    ")\n",
    "print(\"raw response: \\n\", response, \"\\n\")\n",
    "# convert the response to a pandas dataframe and rename the label column as scored_label\n",
    "response_df = pd.read_json(response)\n",
    "response_df = response_df.rename(columns={0: \"scored_label\"})\n",
    "response_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the test dataframe and the response dataframe on the index\n",
    "merged_df = pd.merge(test_df, response_df, left_index=True, right_index=True)\n",
    "merged_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Delete the online endpoint\n",
    "Don't forget to delete the online endpoint, else you will leave the billing meter running for the compute used by the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_ml_client.online_endpoints.begin_delete(name=online_endpoint_name).wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
